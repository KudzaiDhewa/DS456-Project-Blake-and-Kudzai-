[
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data Sources and Preparation",
    "section": "",
    "text": "For our analysis, we selected a sample of ten widely used open-source libraries: five written in Rust and five written in C. Libraries were chosen using a pairwise matching strategy, where each Rust library was matched with a C library that operates in a similar functional domain (e.g., cryptography, networking, parsing) and serves a comparable role within the software ecosystem.\nBecause C is several decades older than Rust, the C libraries in our sample are generally more mature in terms of age and historical usage. To mitigate bias arising from differences in development life cycle stage, we prioritized libraries that appear to be primarily in a maintenance phase rather than undergoing rapid feature expansion. This assessment was informed by our consultation with our domain expert who is very familiar with systems-level open-source development. We supplemented this with extensive internet research.\nThe table below shows the libraries we choose.\n\n\nCode\ncommits &lt;- read.csv(\"Data/FINAL_CSS_WITH_PREDICTION_TIMESERIES.csv\")\n\nlibrary(dplyr)\n\n\n\n\nCode\nlibrary_summary &lt;- commits %&gt;%\n  filter(!is.na(year)) %&gt;%\n  group_by(language, repo) %&gt;%\n  summarise(\n    total_commits = n(),\n    min_year = min(year),\n    max_year = max(year),\n    year_range = paste0(min_year, \"–\", max_year),\n    avg_commits_per_year = round(\n      total_commits / (max_year - min_year + 1),\n      2\n    ),\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(desc(total_commits)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  select(language, repo, total_commits, year_range, avg_commits_per_year)\n\nknitr::kable(\n  library_summary,\n  caption = \"Commit Activity by Language and Repository\",\n  col.names = c(\n    \"Language\",\n    \"Repository\",\n    \"Total Commits\",\n    \"Year Range\",\n    \"Avg. Commits / Year\"\n  )\n)\n\n\n\nCommit Activity by Language and Repository\n\n\nLanguage\nRepository\nTotal Commits\nYear Range\nAvg. Commits / Year\n\n\n\n\nc\nopenssl\n38345\n1998–2025\n1369.46\n\n\nc\nlibcurl\n37157\n1999–2025\n1376.19\n\n\nc\nsqlite\n30862\n2000–2025\n1187.00\n\n\nc\ncoreutils\n30825\n1992–2025\n906.62\n\n\nrust\ncoreutils\n17291\n2013–2025\n1330.08\n\n\nrust\nlimbo\n11385\n2023–2025\n3795.00\n\n\nc\nlibxml2\n7684\n1998–2025\n274.43\n\n\nrust\nrustls\n4598\n2016–2025\n459.80\n\n\nrust\nhyper\n2888\n2014–2025\n240.67\n\n\nrust\nquick-xml\n1711\n1970–2025\n30.55\n\n\n\n\n\n\n\n\nDomain\nC Repository\nRust Repository\n\n\n\n\nXML Parsing\nlibxml2\nquick-xml\n\n\nHTTP/Networking\nlibcurl\nhyper\n\n\nCryptography/TLS\nopenssl\nrustls\n\n\nDatabase\nsqlite\nlimbo\n\n\nSystem Utilities\ncoreutils (GNU)\ncoreutils (uutils)"
  },
  {
    "objectID": "data.html#library-selection",
    "href": "data.html#library-selection",
    "title": "Data Sources and Preparation",
    "section": "",
    "text": "For our analysis, we selected a sample of ten widely used open-source libraries: five written in Rust and five written in C. Libraries were chosen using a pairwise matching strategy, where each Rust library was matched with a C library that operates in a similar functional domain (e.g., cryptography, networking, parsing) and serves a comparable role within the software ecosystem.\nBecause C is several decades older than Rust, the C libraries in our sample are generally more mature in terms of age and historical usage. To mitigate bias arising from differences in development life cycle stage, we prioritized libraries that appear to be primarily in a maintenance phase rather than undergoing rapid feature expansion. This assessment was informed by our consultation with our domain expert who is very familiar with systems-level open-source development. We supplemented this with extensive internet research.\nThe table below shows the libraries we choose.\n\n\nCode\ncommits &lt;- read.csv(\"Data/FINAL_CSS_WITH_PREDICTION_TIMESERIES.csv\")\n\nlibrary(dplyr)\n\n\n\n\nCode\nlibrary_summary &lt;- commits %&gt;%\n  filter(!is.na(year)) %&gt;%\n  group_by(language, repo) %&gt;%\n  summarise(\n    total_commits = n(),\n    min_year = min(year),\n    max_year = max(year),\n    year_range = paste0(min_year, \"–\", max_year),\n    avg_commits_per_year = round(\n      total_commits / (max_year - min_year + 1),\n      2\n    ),\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(desc(total_commits)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  select(language, repo, total_commits, year_range, avg_commits_per_year)\n\nknitr::kable(\n  library_summary,\n  caption = \"Commit Activity by Language and Repository\",\n  col.names = c(\n    \"Language\",\n    \"Repository\",\n    \"Total Commits\",\n    \"Year Range\",\n    \"Avg. Commits / Year\"\n  )\n)\n\n\n\nCommit Activity by Language and Repository\n\n\nLanguage\nRepository\nTotal Commits\nYear Range\nAvg. Commits / Year\n\n\n\n\nc\nopenssl\n38345\n1998–2025\n1369.46\n\n\nc\nlibcurl\n37157\n1999–2025\n1376.19\n\n\nc\nsqlite\n30862\n2000–2025\n1187.00\n\n\nc\ncoreutils\n30825\n1992–2025\n906.62\n\n\nrust\ncoreutils\n17291\n2013–2025\n1330.08\n\n\nrust\nlimbo\n11385\n2023–2025\n3795.00\n\n\nc\nlibxml2\n7684\n1998–2025\n274.43\n\n\nrust\nrustls\n4598\n2016–2025\n459.80\n\n\nrust\nhyper\n2888\n2014–2025\n240.67\n\n\nrust\nquick-xml\n1711\n1970–2025\n30.55\n\n\n\n\n\n\n\n\nDomain\nC Repository\nRust Repository\n\n\n\n\nXML Parsing\nlibxml2\nquick-xml\n\n\nHTTP/Networking\nlibcurl\nhyper\n\n\nCryptography/TLS\nopenssl\nrustls\n\n\nDatabase\nsqlite\nlimbo\n\n\nSystem Utilities\ncoreutils (GNU)\ncoreutils (uutils)"
  },
  {
    "objectID": "data.html#data-sources-and-acquisition",
    "href": "data.html#data-sources-and-acquisition",
    "title": "Data Sources and Preparation",
    "section": "0.2 Data Sources and Acquisition",
    "text": "0.2 Data Sources and Acquisition\nFor each library in our sample, we retrieved the complete commit history from its official GitHub repository using the GitHub REST API. GitHub was chosen as the data source because it provides standardized, time-stamped records of development activity across projects and is the primary collaboration platform for all libraries in our sample.\nEach commit record includes:\n\nA unique commit identifier\nA textual commit message describing the change\nA commit diff summarizing code changes\nThe author of the commit\nA timestamp indicating when the commit was authored\n\nThese commit-level records form the core dataset used in our analysis. An individual row in the dataset corresponds to a single commit made to a given library."
  },
  {
    "objectID": "data.html#key-variables",
    "href": "data.html#key-variables",
    "title": "Data Sources and Preparation",
    "section": "0.3 Key Variables",
    "text": "0.3 Key Variables\nThe table below describes the primary variables extracted from the Github commit data\n\n\n\n\n\n\n\n\nVariable\nDescription\nType\n\n\n\n\ncommit_diff\nTextual summary of code changes associated with a commit, including files changed and lines added or removed\nText (semi-structured)\n\n\ncommit_message\nFree-text message describing the purpose or intent of the commit\nText\n\n\ntimestamp\nDate and time when the commit was authored\nDatetime\n\n\nauthor\nUsername or identifier of the contributor who authored the commit\nCategorical\n\n\nlibrary\nName of the open-source library associated with the commit\nCategorical\n\n\nlanguage\nProgramming language of the library (C or Rust)\nCategorical\n\n\n\n\n\nCode\ncommits &lt;- read.csv(\"Data/FINAL_CSS_WITH_PREDICTION_TIMESERIES.csv\")\n\n\nTo ensure accurate interpretation of this raw data—specifically regarding the subtleties of memory management and concurrency in systems languages—we employed a “Pre-Validation” strategy. This involved a targeted “Crash Course” methodology where we cataloged language-specific failure modes (e.g., “double-free” errors in C vs. “borrow checker violations” in Rust). This domain knowledge was applied to a subset of commits to validate our labeling schema, ensuring that our downstream classifications reflected true engineering intent rather than keywords."
  },
  {
    "objectID": "data.html#variables-after-llm-classification",
    "href": "data.html#variables-after-llm-classification",
    "title": "Data Sources and Preparation",
    "section": "0.4 Variables after LLM classification",
    "text": "0.4 Variables after LLM classification\nThe table below describes the primary variables extracted and engineered for our final dataset.\n\n\n\n\n\n\n\n\nVariable\nDescription\nType\n\n\n\n\ncommit_id\nUnique SHA-1 identifier for the commit.\nString\n\n\ncommit_diff\nSmartly truncated textual summary of code changes.\nText\n\n\ncommit_message\nFree-text message describing the intent of the commit.\nText\n\n\nlanguage\nProgramming language of the library (C or Rust).\nCategorical\n\n\nrepo\nName of the open-source library.\nCategorical\n\n\ncategory\nThe inferred intent (e.g., “Memory Safety”, “Feature”).\nCategorical\n\n\ncomplexity\nLLM-assessed cognitive load (1-5).\nInteger\n\n\nentropy\nNumber of files modified in the commit.\nInteger\n\n\nchurn\nTotal lines added and removed.\nInteger\n\n\nccs_score\nCalculated Commit Complexity Score (derived metric).\nFloat\n\n\nyear\nYear the commit was authored.\nInteger"
  },
  {
    "objectID": "data.html#data-cleaning",
    "href": "data.html#data-cleaning",
    "title": "Data Sources and Preparation",
    "section": "0.5 Data Cleaning",
    "text": "0.5 Data Cleaning\nRaw git data is inherently noisy. We implemented a custom Extract-Transform-Load (ETL) pipeline to prepare the data for analysis.\n1. Unicode Sanitization Legacy C repositories (specifically libxml2) contain historical commits with non-UTF-8 encodings (e.g., Latin-1). We implemented a sanitization layer using Python’s surrogateescape error handler to ensure all textual data was valid UTF-8 before processing.\n2. Smart Diff Truncation (“The Accordion”) A major challenge in code analysis is the context window limit of LLMs. A raw diff can span thousands of lines (e.g., auto-generated documentation or build artifacts). To address this, we developed a “Smart Truncation” algorithm using the unidiff library. * Noise Filtering: Files related to documentation (.html), assets, and lockfiles were stripped of content, preserving only the filename. * Accordion Logic: For large code files, the algorithm preserves the “Head” (first 5 lines) and “Tail” (last 5 lines) of a change hunk while truncating the repetitive middle. * Impact: By reducing massive functional blocks (often 100+ lines) to 10-line context summaries and eliminating non-semantic build artifacts, we achieved an estimated token reduction of &gt;60% compared to raw full-text diffs, allowing for efficient batch processing without losing semantic context."
  },
  {
    "objectID": "data.html#commit-classification-using-large-language-models",
    "href": "data.html#commit-classification-using-large-language-models",
    "title": "Data Sources and Preparation",
    "section": "1.1 Commit Classification Using Large Language Models",
    "text": "1.1 Commit Classification Using Large Language Models\nTo distinguish between different types of development activity, we classified each commit as either maintenance-oriented or feature-oriented based on its commit message and diff. Maintenance commits include bug fixes, refactoring, performance improvements, and dependency updates, while feature commits introduce new functionality or expand existing capabilities.\nThis classification was performed using a large language model (LLM), which was prompted with the commit message and a summarized diff. In addition to categorical classification, the LLM was asked to assign a relative complexity score reflecting the estimated effort required to complete the task represented by the commit.\nTo distinguish between different types of development activity, we classified each commit into one of five mutually exclusive categories\n\n1.1.1 Classification Schema\n\nMemory Safety & Robustness: Fixes for leaks, segfaults, bounds checks, unsafe blocks, and panics.\nConcurrency & Thread Safety: Fixes for race conditions, deadlocks, atomicity violations, and Send/Sync trait issues.\nLogic & Correctness: Fixes for functional bugs, state machine errors, and specification compliance.\nBuild, Refactor & Internal: Non-functional changes, CI/CD, testing, style changes, and dependency management.\nFeature & Value Add: Implementation of new capabilities, APIs, or performance optimizations.\n\nThis classification was performed using a large language model (LLM), which was prompted with the commit message and the summarized diff. In addition to categorical classification, the LLM assigned a relative complexity score (1-5) reflecting the conceptual knowledge required for the task."
  },
  {
    "objectID": "data.html#llm-configuration-and-training",
    "href": "data.html#llm-configuration-and-training",
    "title": "Data Sources and Preparation",
    "section": "1.2 LLM Configuration and Training",
    "text": "1.2 LLM Configuration and Training\n\nModel Used: Google Gemini 2.0 Flash (Fine-Tuned).\nInfrastructure: Google Cloud Platform (Vertex AI).\nSynthetic Augmentation: To address class imbalances, we augmented the training set with high-quality synthetic examples of C and Rust concurrency bugs. This ensured the model could recognize these critical but infrequent patterns.\nInference: The full dataset was processed using Vertex AI Batch Prediction, classifying all 182,746 commits.\nPrompt Structure: For the prompt structure the system instructions we used was “Role: Expert C/Rust Reviewer. Task: Classify commit. Return ONLY valid JSON.” “Categories (Choose one strictly):” “- ‘Memory Safety & Robustness’ (Bounds, pointers, leaks, unsafe blocks, panics)” “- ‘Concurrency & Thread Safety’ (Atomics, locks, races, Send/Sync)” “- ‘Logic & Correctness’ (Math, state, functional bugs)” “- ‘Build, Refactor & Internal’ (CI, tests, style, deps, cleanup)” “- ‘Feature & Value Add’ (New capabilities, perf)” “Metrics:” “- feat: Boolean (True if Category is Feature)” “- sec: Boolean (True if fixing crash/vuln)” “- comp: Integer 1 (Trivial) to 5 (Complex)” “- reas: String (Max 15 words)” “JSON Schema:” “{\"cat\": \"Category Name\", \"feat\": bool, \"sec\": bool, \"comp\": int, \"reas\": \"str\"}” ) and each user field was f”Lang: {language} Msg: {commit_message}:“.\n\n\n1.2.1 Gold Standard Labeling Methodology (HITL)\nTo create the training dataset, we employed a Human-in-the-Loop (HITL) workflow assisted by a “Mini-Lesson” prompt structure. 1. Mini-Lesson Generation: For every unlabeled commit, an LLM generated the standard classification JSON plus an extended “Mini-Lesson.” This lesson explained the key syntax involved, the underlying concept, and the reasoning for the specific category value. 2. Human Verification: The human labeler reviewed the commit superficially alongside the Mini-Lesson. The label was confirmed only if the Diff, the Category, and the Lesson explanation aligned perfectly. 3. Ensemble Voting: In cases of discrepancy or ambiguity, a secondary, independent LLM was queried on the same case. The final label was determined via a voting system (Human + Initial LLM + Secondary LLM) to ensure consensus."
  },
  {
    "objectID": "data.html#validation",
    "href": "data.html#validation",
    "title": "Data Sources and Preparation",
    "section": "1.3 Validation",
    "text": "1.3 Validation\nTo assess classification reliability, a subset of commits was manually reviewed and compared against the LLM’s outputs. Disagreements were examined qualitatively to identify systematic errors or ambiguities. While LLM-based classification introduces some subjectivity, it enables consistent interpretation of free-text commit messages at scale and provides a practical approach for large-scale maintenance analysis.\nValidation of the model’s performance was conducted via Google Cloud Platform’s internal evaluation framework. During the fine-tuning process, Vertex AI automatically reserved a random 80/20 split (80% training, 20% validation). The model’s loss metrics on this holdout validation set were monitored to ensure generalization and prevent overfitting to the labeled examples."
  },
  {
    "objectID": "data.html#the-commit-complexity-score-ccs",
    "href": "data.html#the-commit-complexity-score-ccs",
    "title": "Data Sources and Preparation",
    "section": "1.4 The Commit Complexity Score (CCS)",
    "text": "1.4 The Commit Complexity Score (CCS)\nFinally, we calculated a derived metric to quantify the total load of a change. The Commit Complexity Score (CCS) combines the qualitative assessment of the LLM with quantitative metrics from Git:\n\\[ CCS = (w_1 \\cdot C_{cog}) + (w_2 \\cdot \\log_{10}(Entropy + 1)) + (w_3 \\cdot \\log_{10}(Churn + 1)) \\]\nWhere \\(C_{cog}\\) is the LLM-assessed complexity, and \\(Entropy\\) and \\(Churn\\) are logarithmic scalings of files touched and lines changed, respectively."
  },
  {
    "objectID": "appendix.html",
    "href": "appendix.html",
    "title": "Appendix",
    "section": "",
    "text": "1.) The dataset used in this analysis is available here.\n2.) Link to repo\nReferences:\n\nLibxml2 Becomes Officially Unmaintained After Maintainer Steps Down: https://linuxiac.com/libxml2-becomes-officially-unmaintained/\nWhat Makes Rust Safer Than C: https://knathanael.com/posts/what_makes_rust_safer_than_c/\nRust in Android: move fast and fix things: https://security.googleblog.com/2025/11/rust-in-android-move-fast-fix-things.html\n\nAI usage statement: This project used generative AI tools to assist with classifying GitHub commits into feature and maintenance categories, assigning maintenance subtypes, and estimating a rough complexity score based on commit messages and diffs. AI was also used to support code debugging and to improve clarity and conciseness of written explanations. All data collection, analytical design, interpretation of results, and final conclusions were produced by the authors."
  },
  {
    "objectID": "limitations.html",
    "href": "limitations.html",
    "title": "Limitations",
    "section": "",
    "text": "C is much more mature than Rust, making it challenging to find truly comparable libraries.\nRegressions to validate correlation between reduction in memory safety maintenance and increase in feature work are missing. This is an area for future exploration.\nLLM-based complexity score might not be the most accurate measurement approach as complexity is somewhat object and might vary from developer to developer."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Maintenance Burden Estimation: A comparative study between C and Rust Open Source Packages",
    "section": "",
    "text": "Through engagements with our domain expert, Josh Aas, we learnt about a C Open Source Library called libxml2. This is a a widely used XML parser that is used to create and manipulate XML documents. It comes preinstalled on most UNIX-based systems, including Linux, Android, iOS, macOS, and ChromeOS. However, this critical open-source library is currently running short of maintainers and our expert is in the process of figuring out if it is reasonable to migrate the library to Rust instead of sourcing maintainers for it in C.\n\n\nAs a broader research topic to try and help him answer this question we decided to try and estimate the maintenance burden of C libraries versus Rust libraries with hope that our data centric results will help the expert make a more informed decision.\nC is a mature systems programming language that originated in the 1970s, and Rust is a much younger language with performance comparable to C that began development in the 2010s. Rust is widely recognized for being more memory safe than C because its compiler enforces strict rules about how memory is used, preventing many common memory errors before the code even runs. In contrast, C allows unrestricted memory access, meaning the compiler will happily build programs even if they contain unsafe memory operations, leaving it up to the programmer to catch mistakes. As a result, there is a general consensus that programmers make fewer memory-related errors when coding in Rust compared to C because Rust’s guardrails catch many mistakes at compile time, whereas C provides almost no such protections. Memory safety is important because most serious software bugs come from memory errors such as security vulnerabilities, crasher, and corrupted data. To learn more about memory safety and the differences between Rust and C reference this article: What Makes Rust Safer Than C\nThis information is important because it informs our initial hypothesis that rust allows less mistakes in the development phase than C and therefore requires less maintenance than C in the long run."
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Maintenance Burden Estimation: A comparative study between C and Rust Open Source Packages",
    "section": "",
    "text": "Through engagements with our domain expert, Josh Aas, we learnt about a C Open Source Library called libxml2. This is a a widely used XML parser that is used to create and manipulate XML documents. It comes preinstalled on most UNIX-based systems, including Linux, Android, iOS, macOS, and ChromeOS. However, this critical open-source library is currently running short of maintainers and our expert is in the process of figuring out if it is reasonable to migrate the library to Rust instead of sourcing maintainers for it in C.\n\n\nAs a broader research topic to try and help him answer this question we decided to try and estimate the maintenance burden of C libraries versus Rust libraries with hope that our data centric results will help the expert make a more informed decision.\nC is a mature systems programming language that originated in the 1970s, and Rust is a much younger language with performance comparable to C that began development in the 2010s. Rust is widely recognized for being more memory safe than C because its compiler enforces strict rules about how memory is used, preventing many common memory errors before the code even runs. In contrast, C allows unrestricted memory access, meaning the compiler will happily build programs even if they contain unsafe memory operations, leaving it up to the programmer to catch mistakes. As a result, there is a general consensus that programmers make fewer memory-related errors when coding in Rust compared to C because Rust’s guardrails catch many mistakes at compile time, whereas C provides almost no such protections. Memory safety is important because most serious software bugs come from memory errors such as security vulnerabilities, crasher, and corrupted data. To learn more about memory safety and the differences between Rust and C reference this article: What Makes Rust Safer Than C\nThis information is important because it informs our initial hypothesis that rust allows less mistakes in the development phase than C and therefore requires less maintenance than C in the long run."
  },
  {
    "objectID": "index.html#research-questions",
    "href": "index.html#research-questions",
    "title": "Maintenance Burden Estimation: A comparative study between C and Rust Open Source Packages",
    "section": "2 Research Questions",
    "text": "2 Research Questions\nRQ1:\nIs the maintenance burden of open-source libraries lower for projects written in Rust compared to those written in C?\nRQ2:\nWhat maintenance activities are most common in C vs Rust open source libraries?"
  },
  {
    "objectID": "index.html#why-this-matters",
    "href": "index.html#why-this-matters",
    "title": "Maintenance Burden Estimation: A comparative study between C and Rust Open Source Packages",
    "section": "3 Why This Matters",
    "text": "3 Why This Matters\nThis matters because it directly influences our expert’s decision of migrating the libxml2 library from C to Rust."
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "Results",
    "section": "",
    "text": "Figure 1: Difference in Commit Focus (C vs. Rust). Positive values indicate a higher share of effort in C; negative values indicate a higher share in Rust. All categories in the visualization are Maintenance except ‘Feature & Value Add’\n\n\n\n\n\n\n\n\nThe data demonstrates a clear resource trade-off. In every functional domain analyzed (XML, HTTP, TLS, etc.), C projects show a deficit in Feature & Value Add work that corresponds almost directly to their surplus in Maintenance work\nThe purple bars (Memory Safety) are consistently positive across all domains. This confirms that memory safety maintenance is a more common occurrence on C projects. In the XML domain (libxml2 vs. quick-xml), this tax accounts for nearly 20% of the total maintenance differential.\nThe Rust divident: The green bars (Feature & Value Add) are consistently negative, indicating higher activity in Rust. This suggests that the time saved by not fixing memory bugs in Rust is reinvested directly into innovation and feature development.\n\n\nStrategic Implication: C forces a focus fixing the past Memory safety issues and other forms of maintenance whereas Rust enables a focus on growth and adding newer features."
  },
  {
    "objectID": "results.html#what-are-developers-focusing-on-maintenance-feature",
    "href": "results.html#what-are-developers-focusing-on-maintenance-feature",
    "title": "Results",
    "section": "",
    "text": "Figure 1: Difference in Commit Focus (C vs. Rust). Positive values indicate a higher share of effort in C; negative values indicate a higher share in Rust. All categories in the visualization are Maintenance except ‘Feature & Value Add’\n\n\n\n\n\n\n\n\nThe data demonstrates a clear resource trade-off. In every functional domain analyzed (XML, HTTP, TLS, etc.), C projects show a deficit in Feature & Value Add work that corresponds almost directly to their surplus in Maintenance work\nThe purple bars (Memory Safety) are consistently positive across all domains. This confirms that memory safety maintenance is a more common occurrence on C projects. In the XML domain (libxml2 vs. quick-xml), this tax accounts for nearly 20% of the total maintenance differential.\nThe Rust divident: The green bars (Feature & Value Add) are consistently negative, indicating higher activity in Rust. This suggests that the time saved by not fixing memory bugs in Rust is reinvested directly into innovation and feature development.\n\n\nStrategic Implication: C forces a focus fixing the past Memory safety issues and other forms of maintenance whereas Rust enables a focus on growth and adding newer features."
  },
  {
    "objectID": "results.html#quantifying-the-memory-safety-gap",
    "href": "results.html#quantifying-the-memory-safety-gap",
    "title": "Results",
    "section": "2 Quantifying the Memory Safety Gap",
    "text": "2 Quantifying the Memory Safety Gap\nThis section drills down into the specific distribution of maintenance categories to quantify the magnitude of the safety difference.\n\n\n\n\n\n\n\n\nFigure 2: Normalized Category Distribution by Language. Note the disparity in Memory Safety vs. Feature work.\n\n\n\n\n\n\n2.1 Key Findings\n\n3x Reduction in Memory Burden: Our classifier identified that ~12% of all commits in the C sample were related to Memory Safety & Robustness, compared to only ~4% in the Rust sample. This represents a 3x reduction in the frequency of memory-related maintenance events.\nLogic & Correctness: Interestingly, C also shows a higher proportion of general Logic & Correctness fixes. This supports the hypothesis that Rust’s expressive type system (e.g., Option, Result, pattern matching) prevents a class of logic errors at compile time that typically manifest as runtime bugs in C.\nThe Growth Gap: Rust projects show a significantly larger proportion of commits dedicated to “Feature & Value Add,” corroborating the “Rust Dividend” observed in the previous section."
  },
  {
    "objectID": "results.html#cognitive-load-analysis-the-shift-left-effect",
    "href": "results.html#cognitive-load-analysis-the-shift-left-effect",
    "title": "Results",
    "section": "3 Cognitive Load Analysis: The “Shift Left” Effect",
    "text": "3 Cognitive Load Analysis: The “Shift Left” Effect\nHaving established the volume of work, we now analyze the nature of the work using our Commit Complexity Score (CCS).\nNote: CCS is a composite metric derived from code entropy (the number of files affected , churn (number of lines changed) , and amount of cognitive complexity (understand required to carry out that type of maintenance: used LLM to get the cognitive complexity score)\n\n\n\n\n\n\n\n\nFigure 3: Commit Complexity Scores (CCS) by Language. Rust commits show slightly higher complexity on average, indicating a ‘Shift Left’ in cognitive load.\n\n\n\n\n\n\n3.1 Key Findings\n\nHigher Average Complexity in Rust: Rust commits exhibit a slightly higher CCS than their C counterparts. At first glance, this might suggest Rust is “harder” to maintain. However, viewed in context with the Error Profile, a different story emerges.\nPre-compile shift: The higher complexity per commit in Rust reflects the language’s requirement to handle correctness at write-time. Rust forces developers to satisfy the borrow checker and handle errors explicitly before merging.\nFront-Loaded vs. Back-Loaded Cost:\n\nRust: Pays a small “upfront tax” in commit complexity to ensure correctness.\nC: Allows for lower-complexity commits (simpler code) that are often incorrect, resulting in a massive “backend tax” of debugging memory safety issues later.\n\n\n\nConclusion: The data suggests Rust does not eliminate complexity; it moves it. It shifts complexity from the Maintenance Phase (debugging crashes) to the Development Phase (satisfying the compiler), where it is cheaper and safer to manage."
  },
  {
    "objectID": "results.html#domain-specific-consistency",
    "href": "results.html#domain-specific-consistency",
    "title": "Results",
    "section": "4 Domain-Specific Consistency",
    "text": "4 Domain-Specific Consistency\nTo ensure these findings are not artifacts of a single outlier project, we validated the trends across distinct functional domains.\n\n\n\n\n\n\n\n\nFigure 4: Normalized Category Distribution by Repository. The pattern holds across diverse domains.\n\n\n\n\n\n\n4.1 Key Findings\n\nUniversality of the Pattern: Whether in networking (curl vs. hyper), data storage (sqlite vs. limbo), or parsing (libxml2 vs. quick-xml), the structural difference remains consistent: C projects are weighted towards corrective maintenance; Rust projects are weighted towards feature work.\nThe XML Extreme: The contrast is most visible in the XML parsing domain. libxml2 (a mature, widely-used C library) shows a maintenance profile dominated by Logic and Memory fixes, while quick-xml acts as a pure “growth” project. This validates that for parsing-heavy workloads—where memory management is most complex—the benefits of Rust are most pronounced.\n\n\n\nCode\nmaintenance_avg &lt;- commits %&gt;%\n  filter(is_feature == \"False\") %&gt;%                 # maintenance only\n  group_by(language,year) %&gt;%\n  summarise(\n    avg_ccs_score = mean(ccs_score, na.rm = TRUE),\n    n_commits = n(),\n  )\n\n\nmaintenance_avg &lt;- maintenance_avg %&gt;%\n  filter(n_commits &gt;= 3)\n\n\nmaintenance_avg &lt;- commits %&gt;%\n  filter(is_feature == \"False\") %&gt;%                 # maintenance only\n  group_by(language,year) %&gt;%\n  summarise(\n    avg_ccs_score = mean(ccs_score, na.rm = TRUE),\n    n_commits = n(),\n  )\n\n\n\n\nmaintenance_avg &lt;- maintenance_avg %&gt;%\n  filter(n_commits &gt;= 3)\n\n\n\nggplot(\n  maintenance_avg %&gt;% filter(year &gt; 2010),\n  aes(x = year, y = avg_ccs_score, color = language)\n) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 2) +\n  scale_x_continuous(\n    breaks = seq(\n      min(maintenance_avg$year),\n      max(maintenance_avg$year),\n      by = 1\n    )\n  ) +\n  labs(\n    title = \"Average Maintenance CCS Score Over Time\",\n    x = \"Year\",\n    y = \"Average CCS Score\",\n    color = \"Language\",\n \n  ) +\n  theme_classic(base_size = 13) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    legend.position = \"bottom\",\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  \n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\n#| fig-width: 14\n#| fig-height: 8\n#| fig-align: centerd\n\n\n\nmaintenance_cat_avg &lt;- commits %&gt;%\n  filter(category != \"Feature & Value Add\") %&gt;%                 # maintenance only\n  filter(!is.na(category), !is.na(year), !is.na(ccs_score)) %&gt;%\n  group_by(language, category, year) %&gt;%\n  summarise(\n    avg_ccs_score = mean(ccs_score, na.rm = TRUE),\n    n_commits = n(),\n    .groups = \"drop\"\n  ) %&gt;%\n  filter(n_commits &gt;= 3)                             # optional noise filter\n\nggplot(\n  maintenance_cat_avg %&gt;% filter(year &gt; 2010),\n  aes(x = year, y = avg_ccs_score, color = category, group = category)\n) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 1.8) +\n  facet_wrap(~ language, nrow = 1) +\n  scale_x_continuous(\n    breaks = seq(\n      min(maintenance_cat_avg$year, na.rm = TRUE),\n      max(maintenance_cat_avg$year, na.rm = TRUE),\n      by = 1\n    )\n  ) +\n  labs(\n    title = \"Average Maintenance CCS Score Over Time by Category\",\n    x = \"Year\",\n    y = \"Average CCS Score\",\n    color = \"Category\"\n  ) +\n  theme_classic(base_size = 13) +\n  theme(\n    plot.margin = margin(10, 10, 30, 10),\n    plot.title = element_text(\n      hjust = 0.5,\n      face = \"bold\",\n      size = 16\n    ),\n    legend.position = \"bottom\",     # ← vertical legend on the side\n    legend.title = element_text(size = 11),\n    legend.text = element_text(size = 10),\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )\n\n\n\n\n\n\n\n\n\n\n\n4.2 Key Findings\n\nOverall, from the first line graph Rust (blue line) consistent has lower average maintenance complexity scores, which suggests lower long-run maintenance burden.\nFrom the second line graph that breaks it down to categories it seems memory-safety commits (purple line) in Rust tend to be more complex than in C. This is a good gut check for our initial claim that Rust is stricter when it comes to memory safety compared to ”"
  },
  {
    "objectID": "results.html#summary-of-results",
    "href": "results.html#summary-of-results",
    "title": "Results",
    "section": "5 Summary of Results",
    "text": "5 Summary of Results\nOur multi-modal classification pipeline, applied to 180,000 commits, provides strong quantitative evidence for the advantages of Rust over C:\n\nReduction of Risk: Rust reduces the proportion of memory safety maintenance work by approximately 3x.\nReallocation of Resources: There is a near-perfect correlation between the reduction in memory safety maintenance work and the increase in feature development work.\nRust commits are more complex for memory safety, but this upfront investment results in efficient long-term maintenance."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n\nCode\n1 + 1\n\n\n[1] 2"
  },
  {
    "objectID": "feedback.html",
    "href": "feedback.html",
    "title": "Expert Feedback",
    "section": "",
    "text": "Feedback from Josh (Second Consultation) and How We Implemented It\nIn our second consultation with Josh, he provided several key pieces of feedback that we subsequently incorporated throughout the project:\n\nRather than categorizing commits into many fine-grained commit types, we simplified the task by asking an LLM to classify each commit as either feature or maintenance.\nJosh noted that an LLM is likely to perform this classification more accurately, given access to both the commit diff and the commit message.\nHe also suggested that maintenance commits related specifically to security would be particularly informative. As a result, we had the LLM additionally indicate whether a maintenance commit was security-related.\nInstead of focusing solely on the count of security or maintenance commits per library, Josh recommended incorporating a complexity score that reflects the estimated effort required to complete the coding task associated with each commit.\nIn addition to manually validating the classifications made by the LLM he also encouraged us to think carefully about the prompts we use for the LLM.\nUsing this approach, we estimate maintenance burden by weighting maintenance commits by their complexity scores, rather than treating all commits as equally costly.\nFinally, Josh emphasized the importance of carefully selecting pairs of libraries with comparable levels of maturity. While this is challenging given Rust’s relative youth compared to C, this feedback informed our final selection of libraries that are largely past active feature development and primarily in a long-term maintenance phase."
  }
]